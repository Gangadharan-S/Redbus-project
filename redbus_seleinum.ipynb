{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddec313-e8f3-4389-be61-94adb3fb2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Government Bus.\n",
    "Bus_name_links = [\"https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/ktcl/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/astc/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/wbtc-ctc/?utm_source=rtchometile\",\n",
    "                  \"https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc/?utm_source=rtchometile\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "612809f1-b643-46bb-96dc-3e7e32f326ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver                      \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) # pip install webdriver_manager\n",
    "driver.maximize_window()\n",
    "\n",
    "driver.get(\"https://www.redbus.in/\")# Driver will open a redbus page                  \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d8a5a8-5648-4ac0-bfa8-e33d37533cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ceffe814-7a3a-4b7d-a610-e54b5de57aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                               #APSRTC Bus Routes & Timings\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "82529dce-1e2c-4b20-8e91-252a585c8805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Hyderabad to Ongole\n",
      "Successfully completed data extraction for route: Ongole to Hyderabad\n",
      "Successfully completed data extraction for route: Kakinada to Visakhapatnam\n",
      "Successfully completed data extraction for route: Bangalore to Tirupati\n",
      "Successfully completed data extraction for route: Bangalore to Kadapa\n",
      "Successfully completed data extraction for route: Hyderabad to Narasaraopet\n",
      "Successfully completed data extraction for route: Chittoor (Andhra Pradesh) to Bangalore\n",
      "Successfully completed data extraction for route: Visakhapatnam to Kakinada\n",
      "Successfully completed data extraction for route: Narasaraopet to Hyderabad\n",
      "Successfully completed data extraction for route: Bangalore to Chittoor (Andhra Pradesh)\n",
      "Successfully completed data extraction for route: Kadapa to Bangalore\n",
      "Successfully completed data extraction for route: Bangalore to Anantapur (andhra pradesh)\n",
      "Successfully completed data extraction for route: Bangalore to Madanapalli\n",
      "Successfully completed data extraction for route: Hyderabad to Vinukonda\n",
      "Successfully completed data extraction for route: Madanapalli to Bangalore\n",
      "Successfully completed data extraction for route: Vinukonda to Hyderabad\n",
      "Successfully completed data extraction for route: Anantapur (andhra pradesh) to Bangalore\n",
      "Successfully completed data extraction for route: Hyderabad to Guntur (Andhra Pradesh)\n",
      "Successfully completed data extraction for route: Tirupati to Bangalore\n",
      "Successfully completed data extraction for route: Eluru to Hyderabad\n",
      "Successfully completed data extraction for route: Guntur (Andhra Pradesh) to Hyderabad\n",
      "Successfully completed data extraction for route: Bangalore to Kadiri\n",
      "Successfully completed data extraction for route: Macherla (andhra pradesh) to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Kurnool\n",
      "Successfully completed data extraction for route: Rajahmundry to Visakhapatnam\n",
      "Successfully completed data extraction for route: Bangalore to Rayachoti\n",
      "Successfully completed data extraction for route: Hyderabad to Macherla (andhra pradesh)\n",
      "Successfully completed data extraction for route: Kadiri to Bangalore\n",
      "Successfully completed data extraction for route: Vijayawada to Visakhapatnam\n",
      "Successfully completed data extraction for route: Hyderabad to Markapuram\n",
      "Successfully completed data extraction for route: Hyderabad to Chilakaluripet\n",
      "Successfully completed data extraction for route: Rajahmundry to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Addanki\n",
      "Successfully completed data extraction for route: Hyderabad to Rajahmundry\n",
      "Successfully completed data extraction for route: Visakhapatnam to Vijayawada\n",
      "Successfully completed data extraction for route: Chilakaluripet to Hyderabad\n",
      "Successfully completed data extraction for route: Chennai to Tirupati\n",
      "Successfully completed data extraction for route: Rayachoti to Bangalore\n",
      "Successfully completed data extraction for route: Visakhapatnam to Rajahmundry\n",
      "Successfully completed data extraction for route: Nandyal to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Jangareddigudem\n",
      "Successfully completed data extraction for route: Hyderabad to Nandyal\n",
      "Successfully completed data extraction for route: Markapuram to Hyderabad\n",
      "Successfully completed data extraction for route: Addanki to Hyderabad\n",
      "Successfully completed data extraction for route: Kurnool to Vijayawada\n",
      "Successfully completed data extraction for route: Rajahmundry to Vijayawada\n",
      "Successfully completed data extraction for route: Kurnool to Bangalore\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "\n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Apsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "\n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5) \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Apsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23d459b-0c8b-40c1-a327-b809180a8e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b826ae73-a30f-448d-a2b3-bd5c5773e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                        # KSRTC(Kerala) Bus Routes & Timings\n",
    "URL =\"https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile\"\n",
    "\n",
    "# Initialize WebDriver\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "# Load the page\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e311fe7f-7bf6-456a-b6a2-04ad0026b502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Bangalore to Kozhikode\n",
      "Successfully completed data extraction for route: Kozhikode to Ernakulam\n",
      "Successfully completed data extraction for route: Ernakulam to Kozhikode\n",
      "Successfully completed data extraction for route: Mysore to Kozhikode\n",
      "Successfully completed data extraction for route: Bangalore to Kannur (Kerala)\n",
      "Successfully completed data extraction for route: Kozhikode to Mysore\n",
      "Successfully completed data extraction for route: Bangalore to Kalpetta (kerala)\n",
      "Successfully completed data extraction for route: Kalpetta (kerala) to Bangalore\n",
      "Successfully completed data extraction for route: Kannur (Kerala) to Bangalore\n",
      "Successfully completed data extraction for route: Kozhikode to Thiruvananthapuram\n",
      "Successfully completed data extraction for route: Kozhikode to Thrissur\n",
      "Successfully completed data extraction for route: Thiruvananthapuram to Kozhikode\n",
      "Successfully completed data extraction for route: Kottayam to Kozhikode\n",
      "Successfully completed data extraction for route: Kozhikode to Kottayam\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True \n",
    "\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"ksrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "\n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"ksrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cb791ac-ddb2-4b68-8d29-741b6825dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dae5b109-c987-415c-9f8c-6a4368ce9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                            #TGSRTC Bus Routes & Timings\n",
    "URL = \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8d9ba2c-856a-479d-a5e8-adb6bcb4bc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Hyderabad to Vijayawada\n",
      "Successfully completed data extraction for route: Khammam to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Khammam\n",
      "Successfully completed data extraction for route: Hyderabad to Mancherial\n",
      "Successfully completed data extraction for route: Karimnagar to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Guntur (Andhra Pradesh)\n",
      "Successfully completed data extraction for route: Guntur (Andhra Pradesh) to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Karimnagar\n",
      "Successfully completed data extraction for route: Hyderabad to Ongole\n",
      "Successfully completed data extraction for route: Hyderabad to Adilabad\n",
      "Successfully completed data extraction for route: Hyderabad to Visakhapatnam\n",
      "Successfully completed data extraction for route: Hyderabad to Tirupati\n",
      "Successfully completed data extraction for route: Kothagudem to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Nirmal\n",
      "Successfully completed data extraction for route: Hyderabad to Kothagudem\n",
      "Successfully completed data extraction for route: Hyderabad to Anantapur (andhra pradesh)\n",
      "Successfully completed data extraction for route: Hyderabad to Warangal\n",
      "Successfully completed data extraction for route: Godavarikhani to Hyderabad\n",
      "Successfully completed data extraction for route: Jagityal to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Addanki\n",
      "Successfully completed data extraction for route: Hyderabad to Godavarikhani\n",
      "Successfully completed data extraction for route: Kodad to Hyderabad\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True\n",
    "\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Tsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5) \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")  \n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Tsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a4fbd7e-20a7-4def-b648-8e5e0462e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eedfb809-cc2a-4eae-9480-59894dc337d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            #Kadamba Transport Corporation Limited (KTCL) Bus Routes & Timings\n",
    "URL = \"https://www.redbus.in/online-booking/ktcl/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1288c75a-0e98-4990-bc78-7a55d5c9e570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Pune to Goa\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False\n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break \n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"ktcl_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5) \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\") \n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"ktcl_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a73e7d-108b-4ee3-badd-03920013fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e71bd361-95d7-421b-9157-b26b485f6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                         #RSRTC Bus Routes & Timings\n",
    "URL = \"https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88a419e3-9489-4b2e-b615-3b4ad12f9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Jodhpur to Ajmer\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Jodhpur\n",
      "Successfully completed data extraction for route: Beawar (Rajasthan) to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Udaipur to Jodhpur\n",
      "Successfully completed data extraction for route: Sikar to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Aligarh (uttar pradesh) to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Kishangarh to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Aligarh (uttar pradesh)\n",
      "Successfully completed data extraction for route: Jodhpur to Beawar (Rajasthan)\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Kota(Rajasthan)\n",
      "Successfully completed data extraction for route: Udaipur to Pali (Rajasthan)\n",
      "Successfully completed data extraction for route: Kota(Rajasthan) to Udaipur\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Pilani\n",
      "Successfully completed data extraction for route: Pali (Rajasthan) to Udaipur\n",
      "Successfully completed data extraction for route: Sikar to Bikaner\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Bhilwara\n",
      "Successfully completed data extraction for route: Udaipur to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Mathura\n",
      "Successfully completed data extraction for route: Bikaner to Sikar\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False\n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break\n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Rsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5) \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")    \n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Rsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e475a493-d9f9-43bd-a25e-e3867009ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cb5c3bb7-b77c-4818-b81d-1b4c9df1fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        #South Bengal State Transport Corporation (SBSTC) Bus Routes & Timings\n",
    "URL = \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2a8186c5-e65c-461d-924f-14b8ad55c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Haldia to Kolkata\n",
      "Successfully completed data extraction for route: Midnapore to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Midnapore\n",
      "Successfully completed data extraction for route: Jhargram to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Contai (Kanthi)\n",
      "Successfully completed data extraction for route: Kolkata to Nandakumar (west bengal)\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Digha\n",
      "Successfully completed data extraction for route: Kolkata to Suri\n",
      "Successfully completed data extraction for route: Kolkata to Siliguri\n",
      "Successfully completed data extraction for route: Siliguri to Kolkata\n",
      "Successfully completed data extraction for route: Illambazar to Kolkata\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Berhampore (West Bengal)\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Purulia to Durgapur (West Bengal)\n",
      "Successfully completed data extraction for route: Midnapore to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Digha to Barasat (West Bengal)\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break\n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"sbsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "\n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5) \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")  \n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Sbsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e9037c7-5e4b-43f9-ac6e-768857b54464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be2e076e-6c7e-40ed-afe5-66336b017d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                              #HRTC Bus Routes & Timings\n",
    "URL = \"https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8ee08fa-4f8d-4fc7-bf26-dbc69b11a573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Delhi to Shimla\n",
      "Successfully completed data extraction for route: Shimla to Delhi\n",
      "Successfully completed data extraction for route: Chandigarh to Hamirpur (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Hamirpur (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Shimla to Manali\n",
      "Successfully completed data extraction for route: Delhi to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Manali\n",
      "Successfully completed data extraction for route: Delhi to Manali\n",
      "Successfully completed data extraction for route: Manali to Chandigarh\n",
      "Successfully completed data extraction for route: Dharamshala (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Shimla to Chandigarh\n",
      "Successfully completed data extraction for route: Delhi to Hamirpur (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Hamirpur (Himachal Pradesh) to Delhi\n",
      "Successfully completed data extraction for route: Solan to Delhi\n",
      "Successfully completed data extraction for route: Delhi to Nalagarh\n",
      "Successfully completed data extraction for route: Chandigarh to Dharamshala (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Manali to Delhi\n",
      "Successfully completed data extraction for route: Kangra to Chandigarh\n",
      "Successfully completed data extraction for route: Manali to Shimla\n",
      "Successfully completed data extraction for route: Chandigarh to Kullu\n",
      "Successfully completed data extraction for route: Delhi to Solan\n",
      "Successfully completed data extraction for route: Chandigarh to Kangra\n",
      "Successfully completed data extraction for route: Ghumarwin to Chandigarh\n",
      "Successfully completed data extraction for route: Ghumarwin to Delhi\n",
      "Successfully completed data extraction for route: Sunder Nagar (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Palampur to Chandigarh\n",
      "Successfully completed data extraction for route: Kullu to Shimla\n",
      "Successfully completed data extraction for route: Delhi to Dharamshala (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Shimla to Kullu\n",
      "Successfully completed data extraction for route: Dharamshala (Himachal Pradesh) to Shimla\n",
      "Successfully completed data extraction for route: Bilaspur (Himachal Pradesh) to Delhi\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Hrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Hrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7672c73-5396-40bb-804c-de843047be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20431588-1f60-4226-83f8-caff6dc1565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                    #Assam State Transport Corporation (ASTC) OFFERS                                        \n",
    "URL = \"https://www.redbus.in/online-booking/astc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "710ddb6f-2283-4d22-b74f-86647b537914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Tezpur to Guwahati\n",
      "Successfully completed data extraction for route: Guwahati to Tezpur\n",
      "Successfully completed data extraction for route: Nagaon (Assam) to Guwahati\n",
      "Successfully completed data extraction for route: Guwahati to Nagaon (Assam)\n",
      "Successfully completed data extraction for route: Jorhat to Tinsukia\n",
      "Successfully completed data extraction for route: Biswanath Charali to Guwahati\n",
      "Successfully completed data extraction for route: North Lakhimpur to Tezpur\n",
      "Successfully completed data extraction for route: North Lakhimpur to Dibrugarh\n",
      "Successfully completed data extraction for route: Guwahati to Kaliabor\n",
      "Successfully completed data extraction for route: Dibrugarh to North Lakhimpur\n",
      "Successfully completed data extraction for route: North Lakhimpur to Nagaon (Assam)\n",
      "Successfully completed data extraction for route: Gohpur to Guwahati\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break\n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Astc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Astc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "daa82796-03d5-404d-bb0a-1b1ea3ca9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ba76297a-9cd4-4e96-b781-5d24b795399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                        #WBTC (CTC) Bus Routes & Timings\n",
    "URL = \"https://www.redbus.in/online-booking/wbtc-ctc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c70de92d-a5ac-4ce0-b4a5-e4c9b9139cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Kolkata\n",
      "Successfully completed data extraction for route: Midnapore to Kolkata\n",
      "Successfully completed data extraction for route: Digha to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Digha\n",
      "Successfully completed data extraction for route: Digha to Kolkata\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Kolaghat\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Nandakumar (west bengal)\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Contai (Kanthi)\n",
      "Successfully completed data extraction for route: Haldia to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Siliguri\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Debra\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Burdwan\n",
      "Successfully completed data extraction for route: Kolkata to Purulia\n",
      "Successfully completed data extraction for route: Kolkata to Asansol (West Bengal)\n",
      "Successfully completed data extraction for route: Digha to Habra\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False\n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Wbtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")  \n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Wbtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de4c7ef3-ef81-4ef3-bc34-d0bcfe398627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7bce6b61-80e7-4a2e-b1fc-99e259dc02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                               #UPSRTC Bus Routes & Timings\n",
    "URL = \"https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "271bff5f-ac7f-4a82-85fc-3f588904536b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element is not clickable at point (634, 2103)\n  (Session info: chrome=131.0.6778.205)\nStacktrace:\n\tGetHandleVerifier [0x010CEC13+23731]\n\t(No symbol) [0x0105C394]\n\t(No symbol) [0x00F3BE63]\n\t(No symbol) [0x00F85C97]\n\t(No symbol) [0x00F840E9]\n\t(No symbol) [0x00F81D0D]\n\t(No symbol) [0x00F81022]\n\t(No symbol) [0x00F75F57]\n\t(No symbol) [0x00FA1E5C]\n\t(No symbol) [0x00F759A4]\n\t(No symbol) [0x00FA20F4]\n\t(No symbol) [0x00FBB46E]\n\t(No symbol) [0x00FA1BF6]\n\t(No symbol) [0x00F73F35]\n\t(No symbol) [0x00F74EBD]\n\tGetHandleVerifier [0x013AF0D3+3039603]\n\tGetHandleVerifier [0x013C2DEA+3120778]\n\tGetHandleVerifier [0x013BB592+3089970]\n\tGetHandleVerifier [0x011643B0+635984]\n\t(No symbol) [0x01064DCD]\n\t(No symbol) [0x01062068]\n\t(No symbol) [0x01062205]\n\t(No symbol) [0x01054FD0]\n\tBaseThreadInitThunk [0x77557BA9+25]\n\tRtlInitializeExceptionChain [0x7794C0CB+107]\n\tRtlClearBits [0x7794C04F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 123\u001b[0m\n\u001b[0;32m    120\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[116], line 52\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m     all_routes_link\u001b[38;5;241m.\u001b[39mextend(bus_routes_link)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Handle pagination\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhandle_pagination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Save route data to CSV\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[116], line 25\u001b[0m, in \u001b[0;36mhandle_pagination\u001b[1;34m(driver, wait)\u001b[0m\n\u001b[0;32m     22\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mnext_page_button\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ElementNotInteractableException:\n\u001b[0;32m     27\u001b[0m     driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments[0].click();\u001b[39m\u001b[38;5;124m\"\u001b[39m, next_page_button)        \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:380\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    378\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element is not clickable at point (634, 2103)\n  (Session info: chrome=131.0.6778.205)\nStacktrace:\n\tGetHandleVerifier [0x010CEC13+23731]\n\t(No symbol) [0x0105C394]\n\t(No symbol) [0x00F3BE63]\n\t(No symbol) [0x00F85C97]\n\t(No symbol) [0x00F840E9]\n\t(No symbol) [0x00F81D0D]\n\t(No symbol) [0x00F81022]\n\t(No symbol) [0x00F75F57]\n\t(No symbol) [0x00FA1E5C]\n\t(No symbol) [0x00F759A4]\n\t(No symbol) [0x00FA20F4]\n\t(No symbol) [0x00FBB46E]\n\t(No symbol) [0x00FA1BF6]\n\t(No symbol) [0x00F73F35]\n\t(No symbol) [0x00F74EBD]\n\tGetHandleVerifier [0x013AF0D3+3039603]\n\tGetHandleVerifier [0x013C2DEA+3120778]\n\tGetHandleVerifier [0x013BB592+3089970]\n\tGetHandleVerifier [0x011643B0+635984]\n\t(No symbol) [0x01064DCD]\n\t(No symbol) [0x01062068]\n\t(No symbol) [0x01062205]\n\t(No symbol) [0x01054FD0]\n\tBaseThreadInitThunk [0x77557BA9+25]\n\tRtlInitializeExceptionChain [0x7794C0CB+107]\n\tRtlClearBits [0x7794C04F+191]\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break\n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Upsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Upsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "591c8bb6-79fa-4482-8248-f677248c27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0f87723-d3de-480c-be7d-3fc88d70eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                               #Bihar state road transport corporation (BSRTC)\n",
    "URL = \"https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35e446e4-5ad1-4642-91b1-8626d991fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Motihari\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Bettiah\n",
      "Successfully completed data extraction for route: Bettiah to Patna (Bihar)\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Balmiki Nagar (bihar)\n",
      "Successfully completed data extraction for route: Balmiki Nagar (bihar) to Patna (Bihar)\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Purnea\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Darbhanga\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Muzaffarpur (Bihar)\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Chhapra (Bihar)\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Bsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\") \n",
    "\n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Bsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edc64d-33e3-482b-a49a-86a271cab9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
